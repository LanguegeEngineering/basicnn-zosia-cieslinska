# -*- coding: utf-8 -*-
"""first_pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dhpsv287qrz0amvXV-zKEAI1QNsQsolK

### Zadania

1. DodaÄ‡ GPU
"""

import torch
import numpy as np

dtype = torch.float
device = torch.device("cpu")

N, D_in, H, D_out = 16, 4, 0, 1

# Create random input and output data

x_numpy = np.array(    [[0., 0., 0., 1.],
                        [1., 0., 0., 1.],
                        [0., 1., 0., 1.],
                        [0., 0., 1., 1.],
                        [1., 1., 0., 1.],
                        [1., 0., 1., 1.],
                        [0., 1., 1., 1.],
                        [1., 1., 1., 1.],
                        [0., 0., 0., 0.],
                        [1., 0., 0., 0.],
                        [0., 1., 0., 0.],
                        [0., 0., 1., 0.],
                        [1., 1., 0., 0.],
                        [1., 0., 1., 0.],
                        [0., 1., 1., 0.],
                        [1., 1., 1., 0.]])

x = torch.from_numpy(x_numpy).float()
print(x)

y_numpy = np.array(     [[1.],
                         [1.],
                         [1.],
                         [1.],
                         [1.],
                         [1.],
                         [1.],
                         [1.],
                         [0.],
                         [0.],
                         [0.],
                         [0.],
                         [0.],
                         [0.],
                         [0.],
                         [0.]])

y = torch.from_numpy(y_numpy).float()

w = torch.randn(D_in, D_out, device=device, dtype=dtype, requires_grad=True)
print(w)

learning_rate = 1e-4
loss_list = []
for t in range(5):
  y_pred = x.mm(w)

  loss = (y_pred - y).pow(2).sum()
  loss_list.append(loss.item())
  loss.backward()

  with torch.no_grad():
    w -= learning_rate * w.grad
    w.grad.zero_()

plt.plot(loss_list, label = 'loss')
plt.legend()
plt.show()

