# -*- coding: utf-8 -*-
"""numpy_nn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TY_fU7DDUH0vzGOw5loEaScVtJFpvtg6

### Zadania

1. Dodać iteracje do treningu
2. Dodać rysunek zmian strat w kolejnych iteracjach
"""

import numpy as np
import matplotlib.pyplot as plt

# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 16, 4, 0, 1

# Create random input and output data

#np. pasażerowie decydujący o kierunku jazdy: zawsze wygrywa kierowca (pierwszy z prawej) - tu prosty przekaz, ostatnia dana ma być przeszła na wyjście

x_numpy = np.array(    [[0., 0., 0., 1.],
                        [1., 0., 0., 1.],
                        [0., 1., 0., 1.],
                        [0., 0., 1., 1.],
                        [1., 1., 0., 1.],
                        [1., 0., 1., 1.],
                        [0., 1., 1., 1.],
                        [1., 1., 1., 1.],
                        [0., 0., 0., 0.],
                        [1., 0., 0., 0.],
                        [0., 1., 0., 0.],
                        [0., 0., 1., 0.],
                        [1., 1., 0., 0.],
                        [1., 0., 1., 0.],
                        [0., 1., 1., 0.],
                        [1., 1., 1., 0.]])

print(x_numpy.shape) # 16 wierszów, 4 kolumy

y_numpy = np.array(     [[1.],
                         [1.],
                         [1.],
                         [1.],
                         [1.],
                         [1.],
                         [1.],
                         [1.],
                         [0.],
                         [0.],
                         [0.],
                         [0.],
                         [0.],
                         [0.],
                         [0.],
                         [0.]])


print(y_numpy.shape)

# Randomly initialize weights
w = np.random.randn(D_in, D_out) #każda z wartości w wierszu danym mnożona tak, by dać jedną oczekiwaną wartość z wiersza y
#randn z rozkładu gausowskiego

print(w)
print(w.shape)

learning_rate = 1e-2
loss_list = []
wlist = []

# Forward pass: compute predicted y
y_pred = x_numpy.dot(w)
print(y_pred)
#pierwsza predykcja: mnożymy wejście przez wagi

# Compute and print loss
for i in range(50):
  loss = np.square(y_pred - y_numpy).sum() #obliczamy stratę w stosunku do oczekiwanego wyniku

  # Backprop to compute gradients of w1 and w2 with respect to loss
  grad_y_pred = 2.0 * (y_pred - y_numpy) #liczymy pochodną funkcji y^2 -> a więc 2y
  grad_w = x_numpy.T.dot(grad_y_pred)
  #liczymy pochodną od funkcji straty
  #funkcja straty ma jakiś tam wykres - przesuwamy wagi na wykresie loss(wagi) w stronę minimum loss


  # Update weights
  w = w - learning_rate * grad_w
  y_pred = x_numpy.dot(w)
  loss_list.append(loss)



plt.plot(loss_list, label = 'loss')
plt.legend()
plt.show()
print(w) #zeruje pierwsze parametry i jedynkuje ostani

