{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regresja.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYFQmc5Ik-rM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# D_in is input dimension;\n",
        "# D_out is output dimension.\n",
        "\n",
        "D_in, D_out = 1, 1\n",
        "\n",
        "x_numpy = np.arange(11).reshape(11,1)\n",
        "\n",
        "y_numpy = x_numpy * 9.81\n",
        "\n",
        "plt.plot(x_numpy, y_numpy)\n",
        "plt.ylabel('Wartość siły')\n",
        "plt.xlabel('Masa')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYfPId_Ul4cB",
        "colab_type": "text"
      },
      "source": [
        "Sieć neuronowa:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr01gJk9mHca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.from_numpy(x_numpy).float()\n",
        "y = torch.from_numpy(y_numpy).float()\n",
        "\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, D_out)\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "epochs = 10\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for t in range(epochs):\n",
        "    # Forward pass\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    #print(t, loss.item())\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update to parameters\n",
        "    optimizer.step()\n",
        "    \n",
        "y_test = model(x).data.numpy()\n",
        "\n",
        "plt.plot(x_numpy, y_numpy,  label = 'from data', alpha = .5)\n",
        "plt.plot(x_numpy, y_test, 'go', label = 'prediction', alpha = 0.5)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vOA1TKSmQy_",
        "colab_type": "text"
      },
      "source": [
        "### Zadanie \n",
        "\n",
        "Zrobić to samo dla dowolnej zdefiniowanej przez siebie funkcji wielomianowej stopnia co najmniej drugiego. Zaobserwować jak predykcja zachowuje się poza granicami zbioru treningowego.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODA0WKsYlbFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}